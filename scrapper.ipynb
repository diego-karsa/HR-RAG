{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNDP Policies Scrapper\n",
    "\n",
    "This code scrapes policy documents from the UNDP site, downloads them if they are related to Human Resource Management, converts the DOCX files to JSON format, and calculates statistical information about the word counts of these documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import docx\n",
    "import json\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to get direct sublevels from a given URL\n",
    "def get_direct_sublevels(url):\n",
    "    direct_sublevels = set()  # Set to store direct sublevel URLs\n",
    "    response = requests.get(url)  # Make a GET request to the URL\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')  # Parse the HTML content\n",
    "    links = soup.find_all('a', href=True)  # Find all anchor tags with href attribute\n",
    "    for link in links:\n",
    "        href = link['href']\n",
    "        absolute_url = urljoin(url, href)  # Convert relative URL to absolute URL\n",
    "        if absolute_url.startswith(url) and absolute_url != url:\n",
    "            direct_sublevels.add(absolute_url)  # Add the sublevel URL to the set\n",
    "    return direct_sublevels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download a file from a sublevel URL\n",
    "def download_file(sublevel_url, download_folder):\n",
    "    os.makedirs(download_folder, exist_ok=True)  # Create download folder if it doesn't exist\n",
    "    response = requests.get(sublevel_url)  # Make a GET request to the sublevel URL\n",
    "    if response.ok:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')  # Parse the HTML content\n",
    "        # Select the breadcrumb anchor to check if the page is related to HRM\n",
    "        breadcrumb_anchor = soup.select_one('.breadcrumb > ul:nth-child(1) > li:nth-child(2) > a:nth-child(1)')\n",
    "        if breadcrumb_anchor and 'aria-label' in breadcrumb_anchor.attrs and breadcrumb_anchor['aria-label'] == \"Human Resources Management\":\n",
    "            # Find the download section in the policy document page\n",
    "            download_div = soup.find('div', class_='main-policy document-download-card')\n",
    "            if download_div:\n",
    "                # Check for span with specified classes to find the download button\n",
    "                download_span = download_div.find('span', class_=lambda value: value and 'download-btn-position' in value.split())\n",
    "                if download_span:\n",
    "                    download_link = download_span.find('a', href=True)['href']\n",
    "                    file_url = urljoin(sublevel_url, download_link)  # Create the full file URL\n",
    "                    # Extract filename from sublevel URL\n",
    "                    filename = sublevel_url.split('/')[-1] + \".docx\"\n",
    "                    file_path = os.path.join(download_folder, filename)\n",
    "                    # Download and save the file\n",
    "                    with open(file_path, 'wb') as f:\n",
    "                        f.write(requests.get(file_url).content)\n",
    "                    print(f\"Downloaded {filename} to {download_folder}\")\n",
    "                else:\n",
    "                    print(f\"No download link found on {sublevel_url}\")\n",
    "            else:\n",
    "                print(f\"No download section found on {sublevel_url}\")\n",
    "        else:\n",
    "            print(f\"Page {sublevel_url} is not HRM\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve content from {sublevel_url}. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL of the policy pages\n",
    "base_url = \"https://popp.undp.org/policy-page/\"\n",
    "\n",
    "# Get direct sublevel URLs\n",
    "direct_sublevels = get_direct_sublevels(base_url)\n",
    "download_folder = \"policies\"  # Folder to save downloaded policy documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files from each sublevel URL\n",
    "for sublevel_url in direct_sublevels:\n",
    "    download_file(sublevel_url, download_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert DOCX files to JSON format\n",
    "def convert_docx_to_json(docx_folder, json_file):\n",
    "    data = {}\n",
    "\n",
    "    # Loop through DOCX files in the input folder\n",
    "    for root, dirs, files in os.walk(docx_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".docx\"):\n",
    "                docx_file = os.path.join(root, file)\n",
    "                # Load the DOCX file\n",
    "                doc = docx.Document(docx_file)\n",
    "                # Extract text from paragraphs and remove newline characters\n",
    "                text = ' '.join(paragraph.text for paragraph in doc.paragraphs)\n",
    "                # Extract filename without extension\n",
    "                filename = os.path.splitext(os.path.basename(docx_file))[0]\n",
    "                # Add text to dictionary\n",
    "                data[filename] = text\n",
    "\n",
    "    # Write data to JSON file\n",
    "    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input folder and output JSON file\n",
    "docx_folder = \"policies\"\n",
    "json_file = \"policies.json\"\n",
    "\n",
    "# Convert DOCX files to JSON\n",
    "convert_docx_to_json(docx_folder, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum word count: 85\n",
      "Maximum word count: 17288\n",
      "Average word count: 2405.16\n",
      "Standard Deviation: 3364.75\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate statistics for word counts in dictionary values\n",
    "def calculate_stats(data):\n",
    "    word_counts = [len(str(value).split()) for value in data.values()]\n",
    "    min_word_count = min(word_counts)\n",
    "    max_word_count = max(word_counts)\n",
    "    avg_word_count = sum(word_counts) / len(word_counts)\n",
    "    stddev_word_count = statistics.stdev(word_counts)\n",
    "    return min_word_count, max_word_count, avg_word_count, stddev_word_count\n",
    "\n",
    "# Load JSON data from a file\n",
    "with open('policies.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Calculate statistics\n",
    "min_word_count, max_word_count, avg_word_count, stddev_word_count = calculate_stats(data)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Minimum word count: {min_word_count}\")\n",
    "print(f\"Maximum word count: {max_word_count}\")\n",
    "print(f\"Average word count: {avg_word_count:.2f}\")\n",
    "print(f\"Standard Deviation: {stddev_word_count:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
